{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: **Siddharth Prince**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student ID: **23052058**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Probability Theory\n",
    "\n",
    "## Example 1 (Discrete Proababilities): Will I need a raincoat today?\n",
    "\n",
    "Being an international student in Ireland, I've heard people say, \"enjoy the sun when you can\" a lot (for good reason). I know that this example is also really over-used in the probability space, but I'm going with it because it is fitting (future pun intended) to the conversations here in Ireland.  \n",
    "\n",
    "### Goal:  \n",
    "The aim here is to simulate the weather conditions for a year and to then calculate the probability that you'd need a raincoat for a given day based on the given probability distribution for the past data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "The discrete weather conditions that will be considered for this experiment are as follows:  \n",
    "- Clear\n",
    "- Cloudy\n",
    "- Rain\n",
    "- Meatballs?! (Hey, one of the mandatory videos on Bayes Theorem ended with the speaker reading quotes about considering the impossible/crazy. So, don't blame me Ciaran. :) )\n",
    "  \n",
    "Remember that we're performing this experiment with the context of observing the weather patterns in Ireland, specifically Limerick. Hence, it should be fair to assume some prior information/bake in some bias in terms of the simulated random data.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Calculations\n",
    "\n",
    "(Provide details of the manual calculations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option ? (which option did you pick?)\n",
    "\n",
    "(Describe the task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "(Describe the approach you took. Describe also how you used the feedback from the forums to improve your code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Naive Bayes Classifier\n",
    "\n",
    "Data obtained from https://github.com/johnmyleswhite/ML_for_Hackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import dependencies\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Read the data from the .csv, using the first row as the headers of the data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01_heights_weights_genders.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "# Read the data from the .csv, using the first row as the headers of the data\n",
    "data = pandas.read_csv('01_heights_weights_genders.csv',header=0)\n",
    "\n",
    "# Show just the first few samples so we know it's read correctly\n",
    "data.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Discuss: Do you think there is resonable separation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and labels\n",
    "The aim is to predict the gender of the person based on characteristics such as height, weight. So we call what we want to predict the \"label\" and the characteristics the \"features\". This will be covered more later in the module, but is a good enough understanding for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:3] # X is the features in our dataset\n",
    "y = data.iloc[:,0]   # y is the Labels in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "We have a bunch of data from the csv file. What we need to do is decide what of that data we will use to train the algorithm, and what of that data will be used to see how good the result is. More on this later in the module, but you can't use the same data you train with to test the outcome, as it will naturally fit that very well, but you won't catch things like overfitting. \n",
    "\n",
    "There is some science to this, but for now we will randomly select one third for testing, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the algorithm\n",
    "We won't go into the details here, but we will use a Gaussian Naive Bayesian. Use GaussianNB from sklearn to train the model. The Gaussian is needed as we're dealing with sparse, continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "################################\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the algorithm\n",
    "Using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "################################\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
