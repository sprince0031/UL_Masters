{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7d1c42-eea5-4372-a4f4-93bac683b050",
   "metadata": {},
   "source": [
    "### Student details:\n",
    "Student name: **Siddharth Prince**  \n",
    "Student id: **23052058**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ba5b5-f1b5-4818-b6c2-164d5538a2c4",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a71080a-c80f-4ce0-9520-18a26d27c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housekeeping - imports and utility functions\n",
    "import pandas as pd\n",
    "\n",
    "def processNGramData(ngramContent):\n",
    "    data = {'Word': [], 'Count': []}\n",
    "    for word in ngramContent:\n",
    "        dataPoint = word.split('\\t')\n",
    "        data['Word'].append(dataPoint[0])\n",
    "        data['Count'].append(int(dataPoint[1]))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Method to search the bigram data for the seed word and get all corresponding matches.\n",
    "def searchDataFrame(df, searchTerm: str, columnToSearch: str, matchWord: bool=True):\n",
    "    searchRegex = f\"^{searchTerm}$\" if matchWord else searchTerm\n",
    "    return df.loc[df[columnToSearch].str.contains(searchRegex, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81fc53c-dbb6-4be2-a968-03d12afe3f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-30 07:14:37--  https://norvig.com/ngrams/count_1w.txt\n",
      "Resolving norvig.com (norvig.com)... 158.106.138.13\n",
      "Connecting to norvig.com (norvig.com)|158.106.138.13|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4956241 (4.7M) [text/plain]\n",
      "Saving to: ‘count_1w.txt.2’\n",
      "\n",
      "count_1w.txt.2      100%[===================>]   4.73M  4.01MB/s    in 1.2s    \n",
      "\n",
      "2023-10-30 07:14:39 (4.01 MB/s) - ‘count_1w.txt.2’ saved [4956241/4956241]\n",
      "\n",
      "--2023-10-30 07:14:39--  https://norvig.com/ngrams/count_2w.txt\n",
      "Resolving norvig.com (norvig.com)... 158.106.138.13\n",
      "Connecting to norvig.com (norvig.com)|158.106.138.13|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5566017 (5.3M) [text/plain]\n",
      "Saving to: ‘count_2w.txt.2’\n",
      "\n",
      "count_2w.txt.2      100%[===================>]   5.31M  4.15MB/s    in 1.3s    \n",
      "\n",
      "2023-10-30 07:14:41 (4.15 MB/s) - ‘count_2w.txt.2’ saved [5566017/5566017]\n",
      "\n",
      "Number of unigrams:333333 Number of Bigrams: 286358\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23135851162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>13151942776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>12997637966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>12136980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>9081174698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>like</td>\n",
       "      <td>520585287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>service</td>\n",
       "      <td>519537222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>x</td>\n",
       "      <td>508609523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>than</td>\n",
       "      <td>502609275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>find</td>\n",
       "      <td>502043038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word        Count\n",
       "0       the  23135851162\n",
       "1        of  13151942776\n",
       "2       and  12997637966\n",
       "3        to  12136980858\n",
       "4         a   9081174698\n",
       "..      ...          ...\n",
       "95     like    520585287\n",
       "96  service    519537222\n",
       "97        x    508609523\n",
       "98     than    502609275\n",
       "99     find    502043038\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0Uplink verified</td>\n",
       "      <td>523545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0km to</td>\n",
       "      <td>116103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000s of</td>\n",
       "      <td>939476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100s of</td>\n",
       "      <td>539389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100th anniversary</td>\n",
       "      <td>158621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>24th of</td>\n",
       "      <td>327460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>25th anniversary</td>\n",
       "      <td>261023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>25th of</td>\n",
       "      <td>397735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>26th of</td>\n",
       "      <td>271707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>27th of</td>\n",
       "      <td>276619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word   Count\n",
       "0    0Uplink verified  523545\n",
       "1              0km to  116103\n",
       "2            1000s of  939476\n",
       "3             100s of  539389\n",
       "4   100th anniversary  158621\n",
       "..                ...     ...\n",
       "95            24th of  327460\n",
       "96   25th anniversary  261023\n",
       "97            25th of  397735\n",
       "98            26th of  271707\n",
       "99            27th of  276619\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading data\n",
    "\n",
    "# Downloading unigram data\n",
    "!wget https://norvig.com/ngrams/count_1w.txt\n",
    "with open(\"./count_1w.txt\", \"r\") as unigramFile:\n",
    "    unigramContent = unigramFile.read().splitlines()\n",
    "unigrams_df = processNGramData(unigramContent)\n",
    "totalUnigrams = len(unigrams_df)\n",
    "# print(unigramContent[:100])\n",
    "\n",
    "# Downloading bigram data\n",
    "!wget https://norvig.com/ngrams/count_2w.txt\n",
    "with open(\"./count_2w.txt\", \"r\") as bigramFile:\n",
    "    bigramContent = bigramFile.read().splitlines()\n",
    "bigrams_df = processNGramData(bigramContent)\n",
    "totalBigrams = len(bigrams_df)\n",
    "# print(bigramContent[:100])\n",
    "\n",
    "print(f'Number of unigrams:{totalUnigrams} Number of Bigrams: {totalBigrams}')\n",
    "display(unigrams_df.head(100),bigrams_df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a1a12-a633-49dd-879a-e99b07ab0913",
   "metadata": {},
   "source": [
    "## Task 1. a\n",
    "Finding the probability without 1 smoothing\n",
    "\n",
    "### $P(w_{i}|w_{i-1}) = \\frac{c(w_{i-1},w_{i})} {c(w_{i-1})}$  \n",
    "```\n",
    "where, c() -> count of,  \n",
    "       w -> represents the word,  \n",
    "       i -> current index  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1df452-f673-415b-891b-1c13fdd1bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(sentence):\n",
    "    wordList = sentence.split()\n",
    "    sentenceProbability = 1\n",
    "    print(f'sentence = {wordList}\\n')\n",
    "\n",
    "    for i in range(1, len(wordList)):\n",
    "        # unigram count\n",
    "        unigramCount_prev = searchDataFrame(unigrams_df, wordList[i-1], 'Word')['Count'].values[0]\n",
    "        print(f'unigram count for \"{wordList[i-1]}\" = {unigramCount_prev}')\n",
    "\n",
    "        #bigram count\n",
    "        bigram = f'{wordList[i-1]} {wordList[i]}'\n",
    "        bigramCount = searchDataFrame(bigrams_df, bigram, 'Word')['Count'].values[0]\n",
    "        print(f'bigram count for \"{bigram}\" = {bigramCount}')\n",
    "\n",
    "        # bigram probability\n",
    "        bigramProbability = bigramCount/unigramCount_prev\n",
    "        print(f'bigramProbability for {bigram} = {bigramProbability}')\n",
    "\n",
    "        # Multiplying the probability to the total sentence probability\n",
    "        if bigramCount != 0 and unigramCount_prev != 0:\n",
    "            sentenceProbability *= bigramProbability\n",
    "        else:\n",
    "            print(f'The bigram probability for {bigram} is 0. Hence skipping the multiplication to sentence probability.')\n",
    "        print('-----------------------------------------\\n')\n",
    "    print(f'Sentence probability for \"{sentence}\" = {sentenceProbability}\\n')\n",
    "    return sentenceProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8bb0de-4c32-40dd-a4e8-b744f29d8e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence = ['i', 'love', 'you']\n",
      "\n",
      "unigram count for \"i\" = 3086225277\n",
      "bigram count for \"i love\" = 3979312\n",
      "bigramProbability for i love = 0.001289378332053626\n",
      "-----------------------------------------\n",
      "\n",
      "unigram count for \"love\" = 201063526\n",
      "bigram count for \"love you\" = 5428714\n",
      "bigramProbability for love you = 0.02699999402178991\n",
      "-----------------------------------------\n",
      "\n",
      "Sentence probability for \"i love you\" = 3.481320725727335e-05\n",
      "\n",
      "sentence = ['i', 'hate', 'you']\n",
      "\n",
      "unigram count for \"i\" = 3086225277\n",
      "bigram count for \"i hate\" = 876611\n",
      "bigramProbability for i hate = 0.0002840398614232463\n",
      "-----------------------------------------\n",
      "\n",
      "unigram count for \"hate\" = 21274675\n",
      "bigram count for \"hate you\" = 504048\n",
      "bigramProbability for hate you = 0.023692394830943365\n",
      "-----------------------------------------\n",
      "\n",
      "Sentence probability for \"i hate you\" = 6.7295845445659906e-06\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability(\"i love you\") > probability('i hate you')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dfdf9d-b0cc-413e-82c2-9c18d14120cf",
   "metadata": {},
   "source": [
    "## Task 1.b\n",
    "Applying add-one smoothing. We need to add the total word types to the denominator for this to do this.  \n",
    "\n",
    "### $P^{*}(w_{n}|w_{n-1}) = \\frac{c(w_{n-1}, w_{n})+1} {c(w_{n-1})+V}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a3c2c8-b2ac-4c72-9c1c-a878dd1a00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilityAddOne(sentence):\n",
    "    wordList = sentence.split()\n",
    "    sentenceProbability = 1\n",
    "    print(f'sentence = {wordList}\\n')\n",
    "\n",
    "    for i in range(1, len(wordList)):\n",
    "        # unigram count\n",
    "        unigramCount_prev = searchDataFrame(unigrams_df, wordList[i-1], 'Word')['Count'].values[0]\n",
    "        print(f'unigram count for \"{wordList[i-1]}\" = {unigramCount_prev}')\n",
    "\n",
    "        #bigram count\n",
    "        bigram = f'{wordList[i-1]} {wordList[i]}'\n",
    "        bigramCount = searchDataFrame(bigrams_df, bigram, 'Word')['Count'].values[0]\n",
    "        print(f'bigram count for \"{bigram}\" = {bigramCount}')\n",
    "\n",
    "        # bigram probability\n",
    "        bigramProbability = (bigramCount + 1)/(unigramCount_prev + totalUnigrams)\n",
    "        print(f'bigramProbability for {bigram} = {bigramProbability}')\n",
    "\n",
    "        # Multiplying the probability to the total sentence probability\n",
    "        if bigramCount != 0 and unigramCount_prev != 0:\n",
    "            sentenceProbability *= bigramProbability\n",
    "        else:\n",
    "            print(f'The bigram probability for {bigram} is 0. Hence skipping the multiplication to sentence probability.')\n",
    "        print('-----------------------------------------\\n')\n",
    "    print(f'Sentence probability for \"{sentence}\" = {sentenceProbability}\\n')\n",
    "    return sentenceProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81c3384-7041-447a-abcb-7ab65c5b02b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence = ['i', 'love', 'you']\n",
      "\n",
      "unigram count for \"i\" = 3086225277\n",
      "bigram count for \"i love\" = 3979312\n",
      "bigramProbability for i love = 0.001289239409583089\n",
      "-----------------------------------------\n",
      "\n",
      "unigram count for \"love\" = 201063526\n",
      "bigram count for \"love you\" = 5428714\n",
      "bigramProbability for love you = 0.026955311155076156\n",
      "-----------------------------------------\n",
      "\n",
      "Sentence probability for \"i love you\" = 3.475184943869884e-05\n",
      "\n",
      "sentence = ['i', 'hate', 'you']\n",
      "\n",
      "unigram count for \"i\" = 3086225277\n",
      "bigram count for \"i hate\" = 876611\n",
      "bigramProbability for i hate = 0.00028400951051436537\n",
      "-----------------------------------------\n",
      "\n",
      "unigram count for \"hate\" = 21274675\n",
      "bigram count for \"hate you\" = 504048\n",
      "bigramProbability for hate you = 0.023326953599795038\n",
      "-----------------------------------------\n",
      "\n",
      "Sentence probability for \"i hate you\" = 6.625076673669102e-06\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilityAddOne(\"i love you\") > probabilityAddOne('i hate you')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69560d77-4720-4a6f-8219-c42733ebab6c",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Shannon visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f81c77fe-39e2-4803-b593-dfb99e0806e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0Uplink verified</td>\n",
       "      <td>523545</td>\n",
       "      <td>0Uplink</td>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0km to</td>\n",
       "      <td>116103</td>\n",
       "      <td>0km</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000s of</td>\n",
       "      <td>939476</td>\n",
       "      <td>1000s</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100s of</td>\n",
       "      <td>539389</td>\n",
       "      <td>100s</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100th anniversary</td>\n",
       "      <td>158621</td>\n",
       "      <td>100th</td>\n",
       "      <td>anniversary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10am to</td>\n",
       "      <td>376141</td>\n",
       "      <td>10am</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10th and</td>\n",
       "      <td>183715</td>\n",
       "      <td>10th</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10th anniversary</td>\n",
       "      <td>242830</td>\n",
       "      <td>10th</td>\n",
       "      <td>anniversary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10th century</td>\n",
       "      <td>117755</td>\n",
       "      <td>10th</td>\n",
       "      <td>century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10th grade</td>\n",
       "      <td>174046</td>\n",
       "      <td>10th</td>\n",
       "      <td>grade</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word   Count    word1        word2\n",
       "0   0Uplink verified  523545  0Uplink     verified\n",
       "1             0km to  116103      0km           to\n",
       "2           1000s of  939476    1000s           of\n",
       "3            100s of  539389     100s           of\n",
       "4  100th anniversary  158621    100th  anniversary\n",
       "5            10am to  376141     10am           to\n",
       "6           10th and  183715     10th          and\n",
       "7   10th anniversary  242830     10th  anniversary\n",
       "8       10th century  117755     10th      century\n",
       "9         10th grade  174046     10th        grade"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# splitting the bigrams into two separate columns to make processing for Shannon visualisation easier\n",
    "bigrams_df[['word1', 'word2']] = bigrams_df['Word'].str.split(' ', expand=True)\n",
    "bigrams_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "07856a14-081a-49a4-aac7-5f6bcc3957c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannonVisualization(seed=\"<S>\", commonWordCount=10):\n",
    "    seedStop = \"</S>\"\n",
    "    # random.seed(69)\n",
    "    generatedSentence = seed\n",
    "    # Getting the top 10 common words from the unigram data to help terminate the sentence\n",
    "    unigram_df_sorted = unigrams_df.sort_values('Count', ascending=False)\n",
    "    commonWords = np.ravel(unigram_df_sorted.iloc[:commonWordCount, 0:1].values)\n",
    "    print(f'Top 10 common words from the unigrams dataset: {commonWords}')\n",
    "\n",
    "    iterCount = 0\n",
    "    chosenOne = \"\"\n",
    "    print(\"Shannon Visualisation:\")\n",
    "    # Stop sentence generation if </S> is encountered OR common word found, but not before minimum word count in sentence is >= 10\n",
    "    while chosenOne != seedStop and (iterCount < 10 or (chosenOne in commonWords)):\n",
    "        requiredBigrams_df = searchDataFrame(bigrams_df, seed, 'word1')\n",
    "        if requiredBigrams_df.empty:\n",
    "            break\n",
    "        # Getting the sum of all the count values for the bigrams to compute all probabilities\n",
    "        bigramCountSum = requiredBigrams_df['Count'].sum()\n",
    "        \n",
    "        # Computing the probability for each bigram in the data frame according to its frequency\n",
    "        requiredBigrams_df['probability'] = requiredBigrams_df['Count']/bigramCountSum\n",
    "        \n",
    "        # Getting the intervals for all probabilities\n",
    "        requiredBigrams_df = requiredBigrams_df.sort_values('probability', ascending=False)\n",
    "        requiredBigrams_df['interval'] = requiredBigrams_df['probability'].cumsum()\n",
    "        \n",
    "        # Choosing a bigram randomly with the help of the above computed probability intervals\n",
    "        randomProbability = random.random()\n",
    "        chosenOne = requiredBigrams_df[requiredBigrams_df['interval'] >= randomProbability].iloc[0, 3]\n",
    "        \n",
    "        spaces = (len(generatedSentence)-len(seed))*' ' if iterCount > 0 else ''\n",
    "        print(f'{spaces}{seed} {chosenOne}')\n",
    "        generatedSentence += f' {chosenOne}'\n",
    "        seed = chosenOne\n",
    "        iterCount += 1\n",
    "    \n",
    "    return f'{generatedSentence} {seedStop}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "02546d29-da46-471f-bdfd-1c1a3c0fff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 common words from the unigrams dataset: ['the' 'of' 'and' 'to' 'a' 'in' 'for' 'is' 'on' 'that']\n",
      "Shannon Visualisation:\n",
      "<S> phentermine\n",
      "    phentermine on\n",
      "                on the\n",
      "                   the tragic\n",
      "                       tragic death\n",
      "                              death is\n",
      "                                    is not\n",
      "                                       not listed\n",
      "                                           listed as\n",
      "                                                  as the\n",
      "                                                     the mixture\n",
      "\n",
      "Generated sentence from Shannon visualisation method is:\n",
      "<S> phentermine on the tragic death is not listed as the mixture </S>\n"
     ]
    }
   ],
   "source": [
    "shannonSentence = shannonVisualization()\n",
    "print(f'\\nGenerated sentence from Shannon visualisation method is:\\n{shannonSentence}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
