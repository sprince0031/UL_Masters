{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "If you are running python version < 3.7, make sure to install **requests** via pip by running the following line before executing the below code cell.  \n",
    "`pip install requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "54SnPISlEEyN",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# QuirkyGPT\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def chatWithQuirkyGPT(chatText):\n",
    "\n",
    "    api_key = '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'\n",
    "    api_url = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "    conversation = [\n",
    "        {'role': 'system', 'content': 'You are a fun assistant. You have to answer all chats by the user in the most wackiest and fun way possible.'},\n",
    "        {'role': 'user', 'content': chatText}\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'messages': conversation,\n",
    "        'temperature': 0.7,\n",
    "        'max_tokens': 150\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_url, data=json.dumps(params), headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = json.loads(response.text)\n",
    "        assistant_response = data['choices'][0]['message']['content']\n",
    "        print(f\"QuirkyGPT: {assistant_response}\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello, world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vskb4G5kGGqd",
    "outputId": "cd1f0203-e584-4f4c-9916-c2b7447b5ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n",
      "\n",
      "QuirkyGPT: Oh, hello there, world enthusiast! The phrase \"Hello, world!\" is like a chipper greeting from the digital realm. It's the warm embrace of cyberspace, the virtual high-five that says, \"Hey there, universe, I'm here and ready to party!\" So, let's buckle up our cosmic roller skates and venture forth into the technicolor wonderland of code and creativity! Wheee! ðŸŒâœ¨ðŸ’«\n"
     ]
    }
   ],
   "source": [
    "# Hello World code!\n",
    "\n",
    "print(\"Hello, world!\")\n",
    "\n",
    "# Maybe also ask QuirkyGPT what it thinks?\n",
    "print()\n",
    "chatWithQuirkyGPT(\"What do you think of the phrase, 'Hello, world!' ?\")\n",
    "\n",
    "# while (True):\n",
    "#     chatWithChatGPT(input(\"Ask me anything: \"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
