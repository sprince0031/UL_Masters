{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e2d0f4-f392-4852-841a-ba484c24d8c4",
   "metadata": {},
   "source": [
    "## Student details\n",
    "Student name: **Siddharth Prince**  \n",
    "Student id: **23052058**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df0049-3df2-42fe-ab1d-e314571d8e3f",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fedb054-b730-42e8-841a-9ce33c8ff68a",
   "metadata": {},
   "source": [
    "## A. Downloading Peter Norwig's unigram corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82d6a93-3b9f-4b1d-9800-755f5c46c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housekeeping - imports and utility functions (taken from my previous code for Etivity 3)\n",
    "import pandas as pd\n",
    "import jellyfish\n",
    "\n",
    "def processNGramData(ngramContent):\n",
    "    data = {'Word': [], 'Count': []}\n",
    "    for word in ngramContent:\n",
    "        dataPoint = word.split('\\t')\n",
    "        data['Word'].append(dataPoint[0])\n",
    "        data['Count'].append(int(dataPoint[1]))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Method to search the bigram data for the seed word and get all corresponding matches.\n",
    "def searchDataFrame(df, searchTerm: str, columnToSearch: str, matchWord: bool=True):\n",
    "    searchRegex = f\"^{searchTerm}$\" if matchWord else searchTerm\n",
    "    return df.loc[df[columnToSearch].str.contains(searchRegex, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef6da1a-57f3-4fc5-bca4-b7758202924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-03 13:16:49--  https://norvig.com/ngrams/count_1w.txt\n",
      "Resolving norvig.com (norvig.com)... 158.106.138.13\n",
      "Connecting to norvig.com (norvig.com)|158.106.138.13|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4956241 (4.7M) [text/plain]\n",
      "Saving to: ‘count_1w.txt’\n",
      "\n",
      "count_1w.txt        100%[===================>]   4.73M   733KB/s    in 6.8s    \n",
      "\n",
      "2023-11-03 13:16:57 (711 KB/s) - ‘count_1w.txt’ saved [4956241/4956241]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23135851162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>13151942776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>12997637966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>12136980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>9081174698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>like</td>\n",
       "      <td>520585287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>service</td>\n",
       "      <td>519537222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>x</td>\n",
       "      <td>508609523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>than</td>\n",
       "      <td>502609275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>find</td>\n",
       "      <td>502043038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word        Count\n",
       "0       the  23135851162\n",
       "1        of  13151942776\n",
       "2       and  12997637966\n",
       "3        to  12136980858\n",
       "4         a   9081174698\n",
       "..      ...          ...\n",
       "95     like    520585287\n",
       "96  service    519537222\n",
       "97        x    508609523\n",
       "98     than    502609275\n",
       "99     find    502043038\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downloading unigram data\n",
    "!wget https://norvig.com/ngrams/count_1w.txt\n",
    "with open(\"./count_1w.txt\", \"r\") as unigramFile:\n",
    "    unigramContent = unigramFile.read().splitlines()\n",
    "unigrams_df = processNGramData(unigramContent)\n",
    "totalUnigrams = len(unigrams_df)\n",
    "display(unigrams_df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15dc94e-da1c-4397-b786-bfd461af3ac1",
   "metadata": {},
   "source": [
    "## B. Spelling correction function that prints out possible candidates to replace the misspelt word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a5aaad-8be9-4c11-93a7-f475816ddb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unigram count: 588124220187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>P(Word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23135851162</td>\n",
       "      <td>0.039338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>13151942776</td>\n",
       "      <td>0.022363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>12997637966</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>12136980858</td>\n",
       "      <td>0.020637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>9081174698</td>\n",
       "      <td>0.015441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>like</td>\n",
       "      <td>520585287</td>\n",
       "      <td>0.000885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>service</td>\n",
       "      <td>519537222</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>x</td>\n",
       "      <td>508609523</td>\n",
       "      <td>0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>than</td>\n",
       "      <td>502609275</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>find</td>\n",
       "      <td>502043038</td>\n",
       "      <td>0.000854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word        Count   P(Word)\n",
       "0       the  23135851162  0.039338\n",
       "1        of  13151942776  0.022363\n",
       "2       and  12997637966  0.022100\n",
       "3        to  12136980858  0.020637\n",
       "4         a   9081174698  0.015441\n",
       "..      ...          ...       ...\n",
       "95     like    520585287  0.000885\n",
       "96  service    519537222  0.000883\n",
       "97        x    508609523  0.000865\n",
       "98     than    502609275  0.000855\n",
       "99     find    502043038  0.000854\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Computing all the probabilities for each unigram and adding a column to the unigram data frame\n",
    "totalUnigramCount = unigrams_df['Count'].sum()\n",
    "print(f'Total unigram count: {totalUnigramCount}')\n",
    "unigrams_df['P(Word)'] = unigrams_df['Count']/totalUnigramCount\n",
    "display(unigrams_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08038154-1745-4b6e-987b-e209e9540dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonWordSpellingCorrection(nonWord):\n",
    "    splits = [(nonWord[:i], nonWord[i:]) for i in range(len(nonWord) + 1)]\n",
    "    candidates = pd.DataFrame()\n",
    "    for split in splits:\n",
    "        left, right = split\n",
    "        left_candidates = searchDataFrame(unigrams_df, left, 'Word', False)\n",
    "        right_candidates = searchDataFrame(unigrams_df, right, 'Word', False)\n",
    "        # display(left_candidates)\n",
    "        potential_candidates = pd.concat([left_candidates, right_candidates])\n",
    "        # display(potential_candidates)\n",
    "        # for row in potential_candidates:\n",
    "        #     wordToCheck = row['Word'].values[0]\n",
    "        #     print(wordToCheck) #unable to find a way in time to itereate over the df and get the values alone to pass into the function. :(\n",
    "        filtered_candidates = potential_candidates.loc[lambda x: jellyfish.damerau_levenshtein_distance(nonWord, x['Word'].values) <= 2]\n",
    "        candidates = pd.concat([candidates, filtered_candidates])\n",
    "    print(f'nonWord = {nonWord}')\n",
    "    display(candidates)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b952762-07f8-48f2-9ad8-a64f4475e3b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'b': 'ndarray' object cannot be converted to 'PyString'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m candidates_df \u001b[38;5;241m=\u001b[39m \u001b[43mnonWordSpellingCorrection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macress\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 14\u001b[0m, in \u001b[0;36mnonWordSpellingCorrection\u001b[0;34m(nonWord)\u001b[0m\n\u001b[1;32m      9\u001b[0m     potential_candidates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([left_candidates, right_candidates])\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# display(potential_candidates)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# for row in potential_candidates:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#     wordToCheck = row['Word'].values[0]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#     print(wordToCheck) #unable to find a way in time to itereate over the df and get the values alone to pass into the function. :(\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     filtered_candidates \u001b[38;5;241m=\u001b[39m \u001b[43mpotential_candidates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjellyfish\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdamerau_levenshtein_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnonWord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWord\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([candidates, filtered_candidates])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonWord = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnonWord\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1152\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1152\u001b[0m     maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_if_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/common.py:379\u001b[0m, in \u001b[0;36mapply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03mEvaluate possibly callable input using obj and kwargs if it is callable,\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03motherwise return as it is.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m**kwargs\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(maybe_callable):\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmaybe_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_callable\n",
      "Cell \u001b[0;32mIn[33], line 14\u001b[0m, in \u001b[0;36mnonWordSpellingCorrection.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m     potential_candidates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([left_candidates, right_candidates])\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# display(potential_candidates)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# for row in potential_candidates:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#     wordToCheck = row['Word'].values[0]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#     print(wordToCheck) #unable to find a way in time to itereate over the df and get the values alone to pass into the function. :(\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     filtered_candidates \u001b[38;5;241m=\u001b[39m potential_candidates\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mjellyfish\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdamerau_levenshtein_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnonWord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWord\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     15\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([candidates, filtered_candidates])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonWord = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnonWord\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'b': 'ndarray' object cannot be converted to 'PyString'"
     ]
    }
   ],
   "source": [
    "candidates_df = nonWordSpellingCorrection('acress')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b9530-8aeb-4847-bddb-ce0a8b4e3929",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "464b855f-374b-4aa3-805d-ffa6cbd94d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String=acress\n",
      "candidates = [('across', 0.6851851851851852), ('access', 0.1728395061728395), ('acres', 0.1111111111111111), ('actress', 0.021604938271604937), ('caress', 0.009259259259259259)]\n"
     ]
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "def getSpellingSuggestions(word):\n",
    "    return Word(word).spellcheck()\n",
    "\n",
    "print(f'String={\"acress\"}')\n",
    "print(f'candidates = {getSpellingSuggestions(\"acress\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd9e5d-7619-4696-b7b8-3770aefd4dae",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21990acc-6a55-4892-8808-a916e78902cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence=I have good speling\n",
      "Corrected sentence= I have good spelling\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def correctSentence(sentence):\n",
    "    return TextBlob(sentence).correct()\n",
    "\n",
    "print(f'sentence={\"I have good speling\"}\\nCorrected sentence= {correctSentence(\"I have good speling\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
