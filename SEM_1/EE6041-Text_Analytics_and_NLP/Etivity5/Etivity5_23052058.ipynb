{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a496e123-211f-400e-8809-683a7c207615",
   "metadata": {},
   "source": [
    "## Student details\n",
    "Student name: **Siddharth Prince**  \n",
    "Student ID: **23052058**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f84d44-eda2-4455-82fa-b44a6e59e69a",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e688f5-928f-4368-880b-8b61329f2441",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Using the Naive Bayes classifier we can get a classification\n",
    "### $P(c|d) = argmax P(d|c)P(c); c \\epsilon C$  \n",
    "\n",
    "## Calculating priors\n",
    "To calculate the priors, we can divide the number of documents for each class by the total number of documents.  \n",
    "\n",
    "**For prior of class \"GB\"**  \n",
    "Since there are two documents classified under \"GB\", we need to divide that by the total number of classes which is 4.  \n",
    "### $P('GB') = \\frac{count(d \\epsilon 'GB')} {count(d)} => \\frac{2} {4} = 0.5$  \n",
    "\n",
    "Same for prior with class \"IE\"  \n",
    "### $P('IE') = \\frac{count(d \\epsilon 'IE')} {count(d)} => \\frac{2} {4} = 0.5$  \n",
    "\n",
    "## Calculating the conditional probabilities\n",
    "\n",
    "Also, since 'Capital' and 'city' appear once each in either classes of documents, those can be disregarded here as well. Hence, the actual words that contirbute to which class documents are classified into will depend on words that specify the location such as \"London\", \"Oxford\", \"GB\" for class \"GB\" and \"Dublin\", \"Limerick\" and \"Ireland\" for class \"IE\".  \n",
    "\n",
    "Taking the words from document 5 one by one:  \n",
    "\"University\" -> Effective conditional probability is zero as it appears zero number of times in the training data.  \n",
    "\"university\" -> $\\frac{0} {10}$ since it doesn't appear in dataset => $0$  \n",
    "\"of\" -> $\\frac{1} {10}$ since it appears under GB once => $0.1$  \n",
    "\"Limeick\" -> $\\frac{1} {10}$ since it appears under IE once => $0.1$  \n",
    "\"Wolves\" -> $\\frac{0} {10}$ since it doesn't appear in dataset => $0$\n",
    "\n",
    "Effective probability is 0.1 * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26650fcf-77ba-402c-abbe-ad9b443c003d",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745bf033-f2ad-4f12-ad3e-17ac38ed58b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-10 13:26:33--  http://ptrckprry.com/course/ssd/data/positive-words.txt\n",
      "Resolving ptrckprry.com (ptrckprry.com)... 185.199.109.153, 185.199.108.153, 185.199.111.153, ...\n",
      "Connecting to ptrckprry.com (ptrckprry.com)|185.199.109.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://ptrckprry.com/course/ssd/data/positive-words.txt [following]\n",
      "--2023-11-10 13:26:33--  https://ptrckprry.com/course/ssd/data/positive-words.txt\n",
      "Connecting to ptrckprry.com (ptrckprry.com)|185.199.109.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20630 (20K) [text/plain]\n",
      "Saving to: â€˜positive-words.txtâ€™\n",
      "\n",
      "positive-words.txt  100%[===================>]  20.15K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-11-10 13:26:33 (22.1 MB/s) - â€˜positive-words.txtâ€™ saved [20630/20630]\n",
      "\n",
      "--2023-11-10 13:26:33--  http://ptrckprry.com/course/ssd/data/negative-words.txt\n",
      "Resolving ptrckprry.com (ptrckprry.com)... 185.199.109.153, 185.199.110.153, 185.199.108.153, ...\n",
      "Connecting to ptrckprry.com (ptrckprry.com)|185.199.109.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://ptrckprry.com/course/ssd/data/negative-words.txt [following]\n",
      "--2023-11-10 13:26:34--  https://ptrckprry.com/course/ssd/data/negative-words.txt\n",
      "Connecting to ptrckprry.com (ptrckprry.com)|185.199.109.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 46299 (45K) [text/plain]\n",
      "Saving to: â€˜negative-words.txtâ€™\n",
      "\n",
      "negative-words.txt  100%[===================>]  45.21K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2023-11-10 13:26:34 (5.34 MB/s) - â€˜negative-words.txtâ€™ saved [46299/46299]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ptrckprry.com/course/ssd/data/positive-words.txt\n",
    "!wget http://ptrckprry.com/course/ssd/data/negative-words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41098ef5-d674-4381-9132-a23d57c6a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation']\n",
      "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n"
     ]
    }
   ],
   "source": [
    "with open(\"./positive-words.txt\", \"r\") as positiveWordsFile:\n",
    "    positiveWords = positiveWordsFile.read().splitlines()\n",
    "\n",
    "with open(\"./negative-words.txt\", \"r\", encoding='windows-1250') as negativeWordsFile:\n",
    "    negativeWords = negativeWordsFile.read().splitlines()\n",
    "\n",
    "positiveWords = positiveWords[35:]\n",
    "negativeWords = negativeWords[35:]\n",
    "\n",
    "print(positiveWords[:10])\n",
    "print(negativeWords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a1a6a72-11cd-487e-86a3-1eda0929aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSentiment(text):\n",
    "    words = text.split()\n",
    "    negativeCount = 0\n",
    "    positiveCount = 0\n",
    "    for word in words:\n",
    "        if word in positiveWords:\n",
    "            positiveCount += 1\n",
    "        elif word in negativeWords:\n",
    "            negativeCount += 1\n",
    "\n",
    "    if positiveCount > negativeCount:\n",
    "        print(f\"Positive sentiment ðŸ˜Š\\nConfidence: {positiveCount/len(words)}\")\n",
    "    elif positiveCount < negativeCount:\n",
    "        print(f\"Negative sentiment â˜¹ï¸\\nConfidence: {negativeCount/len(words)}\")\n",
    "    else:\n",
    "        print(f\"Neutral sentiment ðŸ˜\\nConfidence: {len(words) - (positiveCount + negativeCount)/len(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a696ede-5508-4f13-b6c1-65dff5889c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sentiment ðŸ˜Š\n",
      "Confidence: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "findSentiment(\"NLP is cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e496a80d-e1df-48b4-a9af-44d28f3b713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive sentiment ðŸ˜Š\n",
      "Confidence: 0.4\n"
     ]
    }
   ],
   "source": [
    "findSentiment(\"NLP is cool and useful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7512c344-c43e-41e4-8ffb-5d512a6c12fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative sentiment â˜¹ï¸\n",
      "Confidence: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "findSentiment(\"NLP is hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bf9d763-40dc-447c-94a1-cf9a21d04297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative sentiment â˜¹ï¸\n",
      "Confidence: 0.4\n"
     ]
    }
   ],
   "source": [
    "findSentiment(\"NLP is hard and useless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "338dea58-7ee7-45fc-befc-441314af5707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral sentiment ðŸ˜\n",
      "Confidence: 6.0\n"
     ]
    }
   ],
   "source": [
    "findSentiment(\"NLP stands for Natural Language Processing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
