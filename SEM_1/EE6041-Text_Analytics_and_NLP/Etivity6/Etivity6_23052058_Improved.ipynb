{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df8c917-7f53-4ac3-9297-f147cd5eb53b",
   "metadata": {},
   "source": [
    "## Student details\n",
    "Student name: **Siddharth Prince**  \n",
    "Student ID: **23052058**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5cb4e-8f8d-4759-9a3c-8b7b98317102",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e580ad9-b71c-4496-8c0d-87029091ace1",
   "metadata": {},
   "source": [
    "### a. Microaveraged Precision, Recall and F1 scores:\n",
    "For microaveraged scores, we sum up all the true positives, false positives and false negatives across all classes and then find out the precision, recall and F1 scores.  \n",
    "\n",
    "**Sum of true positives:**\n",
    "$$TP(Food) + TP(Drink) = 800 + 70 = 870$$  \n",
    "**Sum of false positives:**\n",
    "$$FP(Food) + FP(Drink) = 200 + 30 = 230$$\n",
    "**Sum of false negatives:**\n",
    "$$FN(Food) + FN(Drink) = 200 + 30 = 230$$  \n",
    "**Microaveraged precision:**  \n",
    "$$\\frac{True Positives}{True Positives + False Positives} = \\frac{870}{870 + 230} = 0.791$$  \n",
    "**Microaveraged recall:**  \n",
    "$$\\frac{True Positives}{True Positives + False Negatives} = \\frac{870}{870 + 230} = 0.791$$  \n",
    "**Microaveraged F1 score:**  \n",
    "$$2 * \\frac{microaveraged precision * microaveraged recall}{microaveraged precision + microaveraged recall} = 2 * \\frac{0.791 * 0.791}{0.791 + 0.791} = 0.791$$  \n",
    "In the above case, since precision and recall is the same, the denominator values just cancel out part of the numerator and leaves 0.791 again. Hence here, the microaveraged precision, recall and F1 scores are all equal!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57940f87-56dc-41e7-93b4-62a159906058",
   "metadata": {},
   "source": [
    "### b. Macroaveraged Precision, Recall and F1 scores:\n",
    "For macroaveraged scores, we find the true positives, false positives and false negatives for all classes individually and then find the averages of theses scores.  \n",
    "\n",
    "**Precision score for the \"Food\" class:**  \n",
    "$$\\frac{TP(Food)}{TP(Food) + FP(Food)} = \\frac{800}{800 + 200} = 0.8$$  \n",
    "**Precision score for the \"Drink\" class:**  \n",
    "$$\\frac{TP(Drink)}{TP(Drink) + FP(Drink)} = \\frac{70}{70 + 30} = 0.7$$  \n",
    "**Macroaveraged precision:**  \n",
    "$$\\frac{precision(Food) + precision(Drink)}{n(classes)} = \\frac{0.8 + 0.7}{2} = 0.75$$  \n",
    "**Recall score for the \"Food\" class:**  \n",
    "$$\\frac{TP(Food)}{TP(Food) + FN(Food)} = \\frac{800}{800 + 200} = 0.8$$  \n",
    "**Recall score for the \"Drink\" class:**  \n",
    "$$\\frac{TP(Drink)}{TP(Drink) + FN(Drink)} = \\frac{70}{70 + 30} = 0.7$$  \n",
    "**Macroaveraged recall:**  \n",
    "$$\\frac{recall(Food) + recall(Drink)}{n(classes)} = \\frac{0.8 + 0.7}{2} = 0.75$$  \n",
    "**F1 score for the \"Food\" class:**  \n",
    "$$2 * \\frac{precision(Food) * recall(Food)}{precision(Food) + recall(Food)} = 2 * \\frac{0.8 * 0.8}{0.8 + 0.8} = 0.8$$  \n",
    "**F1 score for the \"Drink\" class:**  \n",
    "$$2 * \\frac{precision(Drink) * recall(Drink)}{precision(Drink) + recall(Drink)} = 2 * \\frac{0.7 * 0.7}{0.7 + 0.7} = 0.7$$  \n",
    "**Macroaveraged F1 score:**  \n",
    "$$\\frac{F1(Food) + F1(Drink)}{n(classes)} = \\frac{0.8 + 0.7}{2} = 0.75$$  \n",
    "Again, since the false positives and false negatives are all the same for either of the classes, all the scores, including the F1 scores work out to be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94527c4-1699-43d0-8792-56865e402c10",
   "metadata": {},
   "source": [
    "### Reason for difference between the micro and macroaveraged F1 scores:\n",
    "In the case of microaveraged F1 score, since we find the precision and recall scores for all the classes combined, the score will tend to skew more towards the class with a higher score. But in the case of macroaveraged F1 score, we find the average of the individual F1 scores of each class. Hence, this will be more towards the middle of both the scores. This is why we've gotten 0.75 for the macroaveraged case as opposed to 0.791 in the microaveraged case (the food class has a higher F1 score and hence it skews more toward this direction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3439a-f2ca-4cc4-ab7a-fb81845f84eb",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e898141-db82-40d1-b7b0-3ea946f8a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util methods\n",
    "def getBagOfWords(wordList):\n",
    "    bagOfWords = {}\n",
    "    for word in wordList:\n",
    "        if word in bagOfWords:\n",
    "            bagOfWords[word] += 1\n",
    "        else:\n",
    "            bagOfWords[word] = 1\n",
    "    return bagOfWords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4320c61-2c10-423a-9b82-518939d23977",
   "metadata": {},
   "source": [
    "The class below may seem like overkill, but it helps to divide the complexity from the naiveBayesClassifier method. I may have also added functionality that on paper doesn't seem necessary for the scope of this etivity, but hey... it's been a while since I felt satisfied coding something. So, sue me. :P (Kidding XD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa96021-09c5-4916-b51b-7ae789b489b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "# A class that will hold all the meta data associated with a class of documents from the test corpus\n",
    "class MegaDoc:\n",
    "    def __init__(self, docClass, megaDocList: List[Tuple] = [], verbose = False):\n",
    "        self.verbose = verbose\n",
    "        self.__docClass = docClass\n",
    "        self.__megaDoc = ''\n",
    "        self.__megaDocLen = 0\n",
    "        self.__docCount = 0\n",
    "        self.__bow= {}\n",
    "        self.update(megaDocList)\n",
    "\n",
    "    def printDocInfo(self):\n",
    "        print('-' * 80 + '\\nMEGA DOC INFO:\\n' + '-' * 80)\n",
    "        print(f'Class: {self.__docClass}')\n",
    "        print(f'Mega Doc length: {self.__megaDocLen}')\n",
    "        print(f'Mega Doc: {self.__megaDoc}')\n",
    "        print(f'Bag of Words representation: {self.__bow}\\n')\n",
    "\n",
    "    def update(self, docList: List[Tuple]):\n",
    "        errorList = []\n",
    "        for docString, docClass in docList:\n",
    "            if docClass != self.__docClass:\n",
    "                errorList.append((docString, docClass))\n",
    "                # raise Exception(f'Please update with doc of class \"{self.__docClass}\". Received class: {docClass}')\n",
    "            else:\n",
    "                self.__megaDoc = str(self.__megaDoc + ' ' + docString.strip()).strip().lower()\n",
    "                self.__docCount += 1\n",
    "                \n",
    "        if not not docList: # re-generate the document attributes such as bof if the passed list is not empty\n",
    "            self.genDocAttributes()\n",
    "            \n",
    "        if self.verbose:\n",
    "            self.printDocInfo()\n",
    "            if not not errorList: # if the error list is not empty, print a list of docs that were not imported\n",
    "                print(f'The following docs were not updated because of class mismatch. Expected class: {self.__docClass}')\n",
    "                print(errorList)\n",
    "\n",
    "    def genDocAttributes(self):\n",
    "        self.__megaDocList = self.__megaDoc.split()\n",
    "        self.__megaDocLen = len(self.__megaDocList)\n",
    "        '''\n",
    "        Using the util function that counts the occurance of each word in a list of strings.\n",
    "        It returns a dictionary with counts for each string.\n",
    "        '''\n",
    "        self.__bow = getBagOfWords(self.__megaDocList)\n",
    "\n",
    "    # Defining the old getter functions\n",
    "    def getDocClass(self):\n",
    "        '''\n",
    "        returns __docClass The class associated with the megaDoc object\n",
    "        '''\n",
    "        return self.__docClass\n",
    "        \n",
    "    def getMegaDoc(self):\n",
    "        '''\n",
    "        returns __megaDoc The 'megaDoc' or the fully concatenated string representation of all documents in the megaDoc\n",
    "        '''\n",
    "        return self.__megaDoc\n",
    "        \n",
    "    def getMegaDocList(self):\n",
    "        '''\n",
    "        returns __megaDocList The list version of the megaDoc string\n",
    "        '''\n",
    "        return self.__megaDocList\n",
    "        \n",
    "    def getMegaDocLen(self):\n",
    "        '''\n",
    "        returns __megaDocLen The total count of words in the megaDoc\n",
    "        '''\n",
    "        return self.__megaDocLen\n",
    "        \n",
    "    def getDocCount(self):\n",
    "        '''\n",
    "        returns __docCount The count of documents that have been imported to the megaDoc object\n",
    "        '''\n",
    "        return self.__docCount\n",
    "        \n",
    "    def getDocBoW(self):\n",
    "        '''\n",
    "        returns __bow The 'Bag of Words' dictionary representation of the megaDoc\n",
    "        '''\n",
    "        return self.__bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5eef83-01e8-43e8-97d0-6391b3de064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note to self: Make the function more general where it can take in any nnumber of classes and process the outputs accordingly.\n",
    "def naiveBayesClassifier(trainingSet, testingSet):\n",
    "    # Creating a dictionary that segregates all docs based on their corresponding class\n",
    "    docClassification = {}\n",
    "    for doc in trainingSet:\n",
    "        docString, docClass = doc\n",
    "        if docClass in docClassification:\n",
    "            docClassification[docClass].append(doc)\n",
    "        else:\n",
    "            docClassification[docClass] = [doc]\n",
    "\n",
    "    # Create a meta dictionary that will hold the megaDoc object and any other feature that needs to be associated with a class\n",
    "    megaDoc_Metas, V_list = {}, []\n",
    "    for docClass in docClassification:\n",
    "        megaDoc = MegaDoc(docClass, docClassification[docClass], verbose=True)\n",
    "        \n",
    "        # Calculating the priors\n",
    "        prior = megaDoc.getDocCount()/len(trainingSet)\n",
    "        megaDoc.prior = prior\n",
    "        print(f'prob_{docClass} = {prior}')\n",
    "        megaDoc_Metas[docClass] = {'megaDoc': megaDoc}\n",
    "        V_list += megaDoc.getMegaDocList()\n",
    "\n",
    "    # Computing a dictionary containing all word types\n",
    "    V = getBagOfWords(V_list)\n",
    "    print(f'\\nV = {V}')\n",
    "    print(f'|V| = {len(V)}\\n')\n",
    "\n",
    "    # Iterating through all the test docs\n",
    "    for test in testingSet:\n",
    "        print('=' * 80)\n",
    "        print(f'Test document = {test}\\n')\n",
    "\n",
    "        # Initialising the document probabilities for each class to its corresponding priors\n",
    "        for docClass in megaDoc_Metas:\n",
    "            megaDoc_Metas[docClass]['docProb'] = megaDoc_Metas[docClass]['megaDoc'].prior\n",
    "        \n",
    "        for word in test[0].split():\n",
    "            word = word.lower()\n",
    "            if word not in V:\n",
    "                continue # Ignore the word if it never appears in the training corpus\n",
    "                \n",
    "            wordProbPrintStr = f'word = \"{word}\"\\t\\t'\n",
    "            for docClass in megaDoc_Metas:\n",
    "                megaDoc = megaDoc_Metas[docClass]['megaDoc']\n",
    "                bow = megaDoc.getDocBoW()\n",
    "                megaDocLen = megaDoc.getMegaDocLen()\n",
    "                \n",
    "                # Computing the conditional probability for the word\n",
    "                if word in bow:\n",
    "                    conditionalProb = (bow[word] + 1)/(megaDocLen + len(V))\n",
    "                else:\n",
    "                    conditionalProb = 1/(megaDocLen + len(V))\n",
    "                \n",
    "                wordProbPrintStr += f'wordConditionalProb_{docClass} = {conditionalProb}\\t\\t'\n",
    "                \n",
    "                # Multiplying to the total document probabilities for each class\n",
    "                megaDoc_Metas[docClass]['docProb'] *= conditionalProb\n",
    "                \n",
    "            print(wordProbPrintStr)\n",
    "\n",
    "        docProbPrintStr = '\\n'\n",
    "        docProbs = []\n",
    "        for docClass in megaDoc_Metas:\n",
    "            docProb = megaDoc_Metas[docClass]['docProb']\n",
    "            docProbPrintStr += f'docProb_{docClass} = {docProb}\\n'\n",
    "            docProbs.append((docClass, docProb))\n",
    "        \n",
    "        # Printing the total document probabilities as per the classes\n",
    "        print(docProbPrintStr)\n",
    "\n",
    "        # Getting a list of classes that have the max document probabilities among all classes\n",
    "        maxProb = max(docProbs, key=lambda x: x[1])[1]\n",
    "        inferredClasses = [docProb[0] for docProb in docProbs if docProb[1] == maxProb]\n",
    "        \n",
    "        # Printing the inferred class as the result\n",
    "        print(f'Inferred class(es) = {\", \".join(inferredClasses)}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53b413-650a-4650-9b68-4a3798399446",
   "metadata": {},
   "source": [
    "### Test case 1:\n",
    "Default test case given for the etivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686f6c4d-28b4-409d-8318-79e152748309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "MEGA DOC INFO:\n",
      "--------------------------------------------------------------------------------\n",
      "Class: -\n",
      "Mega Doc length: 14\n",
      "Mega Doc: just plain boring entirely predictable and lacks energy no surprises and very few laughs\n",
      "Bag of Words representation: {'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 1, 'few': 1, 'laughs': 1}\n",
      "\n",
      "prob_- = 0.6\n",
      "--------------------------------------------------------------------------------\n",
      "MEGA DOC INFO:\n",
      "--------------------------------------------------------------------------------\n",
      "Class: +\n",
      "Mega Doc length: 9\n",
      "Mega Doc: very powerful the most fun film of the summer\n",
      "Bag of Words representation: {'very': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
      "\n",
      "prob_+ = 0.4\n",
      "\n",
      "V = {'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 2, 'few': 1, 'laughs': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
      "|V| = 20\n",
      "\n",
      "================================================================================\n",
      "Test document = ('predictable with no fun', '?')\n",
      "\n",
      "word = \"predictable\"\t\twordConditionalProb_- = 0.058823529411764705\t\twordConditionalProb_+ = 0.034482758620689655\t\t\n",
      "word = \"no\"\t\twordConditionalProb_- = 0.058823529411764705\t\twordConditionalProb_+ = 0.034482758620689655\t\t\n",
      "word = \"fun\"\t\twordConditionalProb_- = 0.029411764705882353\t\twordConditionalProb_+ = 0.06896551724137931\t\t\n",
      "\n",
      "docProb_- = 6.106248727864848e-05\n",
      "docProb_+ = 3.2801672885317154e-05\n",
      "\n",
      "Inferred class(es) = -\n"
     ]
    }
   ],
   "source": [
    "trainingSet = [('just plain boring','-'),('entirely predictable and lacks energy','-'),('no surprises and very few laughs','-'),('very powerful','+'),('the most fun film of the summer','+')]\n",
    "testSet = [('predictable with no fun','?')]\n",
    "naiveBayesClassifier(trainingSet, testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d58e0e-7adf-4b21-8001-6d8fd8564b09",
   "metadata": {},
   "source": [
    "### Test case 2:\n",
    "Test case used for Etivity 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29add69b-6b16-4f5a-af8d-e53f53fc9066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "MEGA DOC INFO:\n",
      "--------------------------------------------------------------------------------\n",
      "Class: GB\n",
      "Mega Doc length: 12\n",
      "Mega Doc: london is the capital of gb oxford is a city in gb\n",
      "Bag of Words representation: {'london': 1, 'is': 2, 'the': 1, 'capital': 1, 'of': 1, 'gb': 2, 'oxford': 1, 'a': 1, 'city': 1, 'in': 1}\n",
      "\n",
      "prob_GB = 0.5\n",
      "--------------------------------------------------------------------------------\n",
      "MEGA DOC INFO:\n",
      "--------------------------------------------------------------------------------\n",
      "Class: IE\n",
      "Mega Doc length: 12\n",
      "Mega Doc: dublin is the capital of ireland limerick is a city in ireland\n",
      "Bag of Words representation: {'dublin': 1, 'is': 2, 'the': 1, 'capital': 1, 'of': 1, 'ireland': 2, 'limerick': 1, 'a': 1, 'city': 1, 'in': 1}\n",
      "\n",
      "prob_IE = 0.5\n",
      "\n",
      "V = {'london': 1, 'is': 4, 'the': 2, 'capital': 2, 'of': 2, 'gb': 2, 'oxford': 1, 'a': 2, 'city': 2, 'in': 2, 'dublin': 1, 'ireland': 2, 'limerick': 1}\n",
      "|V| = 13\n",
      "\n",
      "================================================================================\n",
      "Test document = ('University of Limerick', '?')\n",
      "\n",
      "word = \"of\"\t\twordConditionalProb_GB = 0.08\t\twordConditionalProb_IE = 0.08\t\t\n",
      "word = \"limerick\"\t\twordConditionalProb_GB = 0.04\t\twordConditionalProb_IE = 0.08\t\t\n",
      "\n",
      "docProb_GB = 0.0016\n",
      "docProb_IE = 0.0032\n",
      "\n",
      "Inferred class(es) = IE\n",
      "================================================================================\n",
      "Test document = ('University College Dublin', '?')\n",
      "\n",
      "word = \"dublin\"\t\twordConditionalProb_GB = 0.04\t\twordConditionalProb_IE = 0.08\t\t\n",
      "\n",
      "docProb_GB = 0.02\n",
      "docProb_IE = 0.04\n",
      "\n",
      "Inferred class(es) = IE\n",
      "================================================================================\n",
      "Test document = ('Imperial College London', '?')\n",
      "\n",
      "word = \"london\"\t\twordConditionalProb_GB = 0.08\t\twordConditionalProb_IE = 0.04\t\t\n",
      "\n",
      "docProb_GB = 0.04\n",
      "docProb_IE = 0.02\n",
      "\n",
      "Inferred class(es) = GB\n",
      "================================================================================\n",
      "Test document = ('University of Oxford', '?')\n",
      "\n",
      "word = \"of\"\t\twordConditionalProb_GB = 0.08\t\twordConditionalProb_IE = 0.08\t\t\n",
      "word = \"oxford\"\t\twordConditionalProb_GB = 0.08\t\twordConditionalProb_IE = 0.04\t\t\n",
      "\n",
      "docProb_GB = 0.0032\n",
      "docProb_IE = 0.0016\n",
      "\n",
      "Inferred class(es) = GB\n",
      "================================================================================\n",
      "Test document = ('Ireland & GB', '?')\n",
      "\n",
      "word = \"ireland\"\t\twordConditionalProb_GB = 0.04\t\twordConditionalProb_IE = 0.12\t\t\n",
      "word = \"gb\"\t\twordConditionalProb_GB = 0.12\t\twordConditionalProb_IE = 0.04\t\t\n",
      "\n",
      "docProb_GB = 0.0024\n",
      "docProb_IE = 0.0024\n",
      "\n",
      "Inferred class(es) = GB, IE\n"
     ]
    }
   ],
   "source": [
    "trainingSet = [('London is the Capital of GB', 'GB'), ('Oxford is a city in GB', 'GB'), ('Dublin is the capital of Ireland', 'IE'), ('Limerick is a city in Ireland', 'IE')]\n",
    "testingSet = [('University of Limerick', '?'), ('University College Dublin', '?'), ('Imperial College London', '?'), ('University of Oxford', '?'), ('Ireland & GB', '?')]\n",
    "naiveBayesClassifier(trainingSet, testingSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252a93f-ed98-44d4-9670-04158f998719",
   "metadata": {},
   "source": [
    "### Test case 3:\n",
    "Testing with 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21028a19-7fd8-4a13-b6c4-03949ad98402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "MEGA DOC INFO:\n",
      "--------------------------------------------------------------------------------\n",
      "Class: GB\n",
      "Mega Doc length: 12\n",
      "Mega Doc: london is the capital of gb oxford is a city in gb\n",
      "Bag of Words representation: {'london': 1, 'is': 2, 'the': 1, 'capital': 1, 'of': 1, 'gb': 2, 'oxford': 1, 'a': 1, 'city': 1, 'in': 1}\n",
      "\n",
      "prob_GB = 0.3333333333333333\n",
      "--------------------------------------------------------------------------------\n",
      "MEGA DOC INFO:\n",
      "--------------------------------------------------------------------------------\n",
      "Class: IE\n",
      "Mega Doc length: 12\n",
      "Mega Doc: dublin is the capital of ireland limerick is a city in ireland\n",
      "Bag of Words representation: {'dublin': 1, 'is': 2, 'the': 1, 'capital': 1, 'of': 1, 'ireland': 2, 'limerick': 1, 'a': 1, 'city': 1, 'in': 1}\n",
      "\n",
      "prob_IE = 0.3333333333333333\n",
      "--------------------------------------------------------------------------------\n",
      "MEGA DOC INFO:\n",
      "--------------------------------------------------------------------------------\n",
      "Class: IN\n",
      "Mega Doc length: 13\n",
      "Mega Doc: chennai is a city in india bangalore is the silicon valley of india\n",
      "Bag of Words representation: {'chennai': 1, 'is': 2, 'a': 1, 'city': 1, 'in': 1, 'india': 2, 'bangalore': 1, 'the': 1, 'silicon': 1, 'valley': 1, 'of': 1}\n",
      "\n",
      "prob_IN = 0.3333333333333333\n",
      "\n",
      "V = {'london': 1, 'is': 6, 'the': 3, 'capital': 2, 'of': 3, 'gb': 2, 'oxford': 1, 'a': 3, 'city': 3, 'in': 3, 'dublin': 1, 'ireland': 2, 'limerick': 1, 'chennai': 1, 'india': 2, 'bangalore': 1, 'silicon': 1, 'valley': 1}\n",
      "|V| = 18\n",
      "\n",
      "================================================================================\n",
      "Test document = ('University of Limerick', '?')\n",
      "\n",
      "word = \"of\"\t\twordConditionalProb_GB = 0.06666666666666667\t\twordConditionalProb_IE = 0.06666666666666667\t\twordConditionalProb_IN = 0.06451612903225806\t\t\n",
      "word = \"limerick\"\t\twordConditionalProb_GB = 0.03333333333333333\t\twordConditionalProb_IE = 0.06666666666666667\t\twordConditionalProb_IN = 0.03225806451612903\t\t\n",
      "\n",
      "docProb_GB = 0.0007407407407407406\n",
      "docProb_IE = 0.0014814814814814812\n",
      "docProb_IN = 0.0006937218175511619\n",
      "\n",
      "Inferred class(es) = IE\n",
      "================================================================================\n",
      "Test document = ('University of Oxford', '?')\n",
      "\n",
      "word = \"of\"\t\twordConditionalProb_GB = 0.06666666666666667\t\twordConditionalProb_IE = 0.06666666666666667\t\twordConditionalProb_IN = 0.06451612903225806\t\t\n",
      "word = \"oxford\"\t\twordConditionalProb_GB = 0.06666666666666667\t\twordConditionalProb_IE = 0.03333333333333333\t\twordConditionalProb_IN = 0.03225806451612903\t\t\n",
      "\n",
      "docProb_GB = 0.0014814814814814812\n",
      "docProb_IE = 0.0007407407407407406\n",
      "docProb_IN = 0.0006937218175511619\n",
      "\n",
      "Inferred class(es) = GB\n",
      "================================================================================\n",
      "Test document = ('Ireland & GB', '?')\n",
      "\n",
      "word = \"ireland\"\t\twordConditionalProb_GB = 0.03333333333333333\t\twordConditionalProb_IE = 0.1\t\twordConditionalProb_IN = 0.03225806451612903\t\t\n",
      "word = \"gb\"\t\twordConditionalProb_GB = 0.1\t\twordConditionalProb_IE = 0.03333333333333333\t\twordConditionalProb_IN = 0.03225806451612903\t\t\n",
      "\n",
      "docProb_GB = 0.0011111111111111111\n",
      "docProb_IE = 0.0011111111111111111\n",
      "docProb_IN = 0.00034686090877558093\n",
      "\n",
      "Inferred class(es) = GB, IE\n",
      "================================================================================\n",
      "Test document = ('New Delhi is the capital of India', '?')\n",
      "\n",
      "word = \"is\"\t\twordConditionalProb_GB = 0.1\t\twordConditionalProb_IE = 0.1\t\twordConditionalProb_IN = 0.0967741935483871\t\t\n",
      "word = \"the\"\t\twordConditionalProb_GB = 0.06666666666666667\t\twordConditionalProb_IE = 0.06666666666666667\t\twordConditionalProb_IN = 0.06451612903225806\t\t\n",
      "word = \"capital\"\t\twordConditionalProb_GB = 0.06666666666666667\t\twordConditionalProb_IE = 0.06666666666666667\t\twordConditionalProb_IN = 0.03225806451612903\t\t\n",
      "word = \"of\"\t\twordConditionalProb_GB = 0.06666666666666667\t\twordConditionalProb_IE = 0.06666666666666667\t\twordConditionalProb_IN = 0.06451612903225806\t\t\n",
      "word = \"india\"\t\twordConditionalProb_GB = 0.03333333333333333\t\twordConditionalProb_IE = 0.03333333333333333\t\twordConditionalProb_IN = 0.0967741935483871\t\t\n",
      "\n",
      "docProb_GB = 3.292181069958848e-07\n",
      "docProb_IE = 3.292181069958848e-07\n",
      "docProb_IN = 4.1915319109532787e-07\n",
      "\n",
      "Inferred class(es) = IN\n"
     ]
    }
   ],
   "source": [
    "trainingSet = [('London is the Capital of GB', 'GB'), ('Oxford is a city in GB', 'GB'), ('Dublin is the capital of Ireland', 'IE'), ('Limerick is a city in Ireland', 'IE'), ('Chennai is a city in India', 'IN'), ('bangalore is the Silicon Valley of India', 'IN')]\n",
    "testingSet = [('University of Limerick', '?'), ('University of Oxford', '?'), ('Ireland & GB', '?'), ('New Delhi is the capital of India', '?')]\n",
    "naiveBayesClassifier(trainingSet, testingSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c833ce7-a642-435d-a2df-d156cf36411d",
   "metadata": {},
   "source": [
    "### Result\n",
    "All cases have passed. The new and improved naiveBayesClassifier method is now more robust and generalised. It can handle training and testing sets with a variable number of classes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b56e8-477e-4af0-8d6f-ad388c1741cc",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e19a39df-f980-45b2-bf21-f126d7640710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String = NLP is cool\n",
      "\n",
      "Sentiment(polarity=0.35, subjectivity=0.65)\n",
      "Positive sentiment 🙂\n",
      "Subjectivity: 0.65\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "String = NLP is cool and useful\n",
      "\n",
      "Sentiment(polarity=0.32499999999999996, subjectivity=0.325)\n",
      "Positive sentiment 🙂\n",
      "Subjectivity: 0.325\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "String = NLP is hard\n",
      "\n",
      "Sentiment(polarity=-0.2916666666666667, subjectivity=0.5416666666666666)\n",
      "Negative sentiment 😔\n",
      "Subjectivity: 0.5416666666666666\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "String = NLP is hard and useless\n",
      "\n",
      "Sentiment(polarity=-0.39583333333333337, subjectivity=0.37083333333333335)\n",
      "Negative sentiment 😔\n",
      "Subjectivity: 0.37083333333333335\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "String = NLP stands for Natural Language Processing\n",
      "\n",
      "Sentiment(polarity=0.1, subjectivity=0.4)\n",
      "Neutral sentiment 😐\n",
      "Subjectivity: 0.4\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from textblob import TextBlob\n",
    "\n",
    "def sentimentAnalyser(string):\n",
    "    print(f'String = {string}\\n')\n",
    "    testimonial = TextBlob(string)\n",
    "    sentimentData = testimonial.sentiment\n",
    "    print(sentimentData)\n",
    "    # Changing the range from -0.2 to 0.2 after discussion with Arash. Apparently, this is the threshhold used in practice\n",
    "    if sentimentData.polarity > 0.2:\n",
    "        print('Positive sentiment 🙂')\n",
    "    elif sentimentData.polarity < -0.2:\n",
    "        print('Negative sentiment 😔')\n",
    "    else:\n",
    "        '''\n",
    "        I've kept the threshold for a positive and negative sentiment analysis to require a polarity score of more than 0.2 and less than\n",
    "        0.2 respectively instead of keeping it to a fine margin of just 0.\n",
    "        '''\n",
    "        print('Neutral sentiment 😐')\n",
    "    print(f'Subjectivity: {sentimentData.subjectivity}')\n",
    "    print('-'*80 + '\\n')\n",
    "\n",
    "sentimentAnalyser(\"NLP is cool\")\n",
    "sentimentAnalyser(\"NLP is cool and useful\")\n",
    "sentimentAnalyser(\"NLP is hard\")\n",
    "sentimentAnalyser(\"NLP is hard and useless\")\n",
    "sentimentAnalyser(\"NLP stands for Natural Language Processing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
