Reference slides: [Temporal Difference(TD) Methods](https://learn.ul.ie/d2l/le/lessons/17967/topics/640660)
[Lecture recording](https://ulcampus-my.sharepoint.com/:v:/g/personal/j_j_collins_ul_ie/EQu8P9BCyTROpx0PnpTQ6ScBbKoyxJGtnZEQAEPGzQ804g?referrer=Teams.TEAMS-WEB&referrerScenario=MeetingChicletGetLink.view.view)
## Deep Q-Networks
- Proposed by Google's DeepMind team in NIPS 2013 paper
- Raw state space as input into the network
- #TODO: back to video recording to complete these notes

## CartPole-v0
- Refer lecture slides for code implementation example
- Example of classic control i.e, not as much as control being implemented here as opposed to Atari.
- Line 9 is important in the DQN implementation. Similar to SARSA where there is no 'max' term.
- 